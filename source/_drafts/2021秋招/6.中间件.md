## MQ

继之前的mysql夺命连环之后，我发现我这个标题被好多套用的，什么夺命zookeeper，夺命多线程一大堆，这一次，开始面试题系列MQ专题，消息队列作为日常常见的使用中间件，面试也是必问的点之一，一起来看看MQ的面试题。



### **你们为什么使用mq？具体的使用场景是什么？**

mq的作用很简单，削峰填谷。以电商交易下单的场景来说，正向交易的过程可能涉及到创建订单、扣减库存、扣减活动预算、扣减积分等等。每个接口的耗时如果是100ms，那么理论上整个下单的链路就需要耗费400ms，这个时间显然是太长了。

![mq](https://i.loli.net/2021/03/19/aNF9GLJBAtrK2lQ.jpg)





如果这些操作全部同步处理的话，首先调用链路太长影响接口性能，其次分布式事务的问题很难处理，这时候像扣减预算和积分这种对实时一致性要求没有那么高的请求，完全就可以通过mq异步的方式去处理了。同时，考虑到异步带来的不一致的问题，我们可以通过job去重试保证接口调用成功，而且一般公司都会有核对的平台，比如下单成功但是未扣减积分的这种问题可以通过核对作为兜底的处理方案。

![mq2](https://i.loli.net/2021/03/19/fp6w4Omo75LCUXI.jpg)





使用mq之后我们的链路变简单了，同时异步发送消息我们的整个系统的抗压能力也上升了。



### **那你们使用什么mq？基于什么做的选型？**

我们主要调研了几个主流的mq，kafka、rabbitmq、rocketmq、activemq，选型我们主要基于以下几个点去考虑：

1. 由于我们系统的qps压力比较大，所以性能是首要考虑的要素。
2. 开发语言，由于我们的开发语言是java，主要是为了方便二次开发。
3. 对于高并发的业务场景是必须的，所以需要支持分布式架构的设计。
4. 功能全面，由于不同的业务场景，可能会用到顺序消息、事务消息等。

基于以上几个考虑，我们最终选择了RocketMQ。

![mq-对比](https://i.loli.net/2021/03/19/toh6MxZVqTCu7bs.jpg)



### 顺序问题

因为换电订单有很多的状态，比如：启动充电、开始充电、结束充电。不可能还没开始充电就已经结束充电了。所以需要保证消息的顺序

#### 如何保证消息顺序

kakfa的`topic`是无序的，但是一个`topic`包含有多个`partition`，每个`partition`内部是有序的。

![image-20210405182905087](https://i.loli.net/2021/04/05/R8X1WgVPcrmCZqM.png)

所以，我们只需要保证每个`producer`生产消息的时候，按照一定的规则写到同一个`partition`中即可。之后不同的消费者读不同的`partition`的消息即可

![image-20210405182920599](https://i.loli.net/2021/04/05/mNT7XYtp6oSqICJ.png)

#### 网络不稳定消息顺序性处理

使用数据库维护一个表格。

### 消息的积压

#### 消息体过大

虽说`kafka`号称支持`百万级的TPS`，但从`producer`发送消息到`broker`需要一次网络`IO`，`broker`写数据到磁盘需要一次磁盘`IO`（写操作），`consumer`从`broker`获取消息先经过一次磁盘`IO`（读操作），再经过一次网络`IO`。

![image-20210405183700415](https://i.loli.net/2021/04/05/JzF3cGHUhYtyud1.png)

一次简单的消息从生产到消费过程，需要经过`2次网络IO`和`2次磁盘IO`。如果消息体过大，势必会增加IO的耗时，进而影响kafka生产和消费的速度。消费者速度太慢的结果，就会出现消息积压情况。

#### 优化传输过程中的信息、使用新型的数据传输协议

#### producer写入parttion规则不太好

可能是生产者按照规则写入partition时，一些大体量的信息写入同一个partition。

#### 批量操作导致的消息积压

> `kafka`允许多个`partition`被同组的一个`consumer`消费，但不允许一个`partition`被同组的多个`consumer`消费，可能会造成资源浪费。

#### 存储的数据量过大

其他都正常，但是入库的数据过大，整个消费者消费的响应过长。

### 主键冲突

代码逻辑会先根据主键从表中查询订单是否存在，如果存在则更新状态，不存在才插入数据，没得问题。

但后面仔细思考了一下：

1. 加分布式锁也可能会影响消费者的消息处理速度。
2. 消费者依赖于redis，如果redis出现网络超时，我们的服务就悲剧了。

所以，我也不打算用分布式锁。而是选择使用mysql的`INSERT INTO ...ON DUPLICATE KEY UPDATE`语法

### 重复消费

`kafka`消费消息时支持三种模式：

1. at most once

   最多一次，保证每一条消息commit成功之后，再进行消费处理。==消息可能会丢失，但是不会重复。==

2. at least once

   至少一次，保证每一条消息成功处理之后，再进行commit，==消息不会丢失，但可能会重复。==

3. exactly once

   精确传递一次。将offset作为唯一id与消息同时处理，并且保证处理的原子性。消息只会处理一次，不丢失也不会重复。但这种方式很难做到。

`kafka`默认的模式是`at least once`，但这种模式可能会产生重复消费的问题，所以我们的业务逻辑必须==做幂等设计==，否则可能会产生重复数据。

### **什么是事务、半事务消息？怎么实现的？**

事务消息就是MQ提供的类似XA的分布式事务能力，通过事务消息可以达到分布式事务的最终一致性。

半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。

实现原理如下：

1. 生产者先发送一条半事务消息到MQ
2. MQ收到消息后返回ack确认
3. 生产者开始执行本地事务
4. 如果事务执行成功发送commit到MQ，失败发送rollback
5. 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查
6. 生产者查询事务执行最终状态
7. 根据查询事务状态再次提交二次确认

最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。

