### **说说进程和线程的区别？**

进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是是程序能够并发执行提高资源利用率和吞吐率。

由于进程是资源分配和调度的基本单位，因为进程的创建、销毁、切换产生大量的时间和空间的开销，进程的数量不能太多，而线程是比进程更小的能独立运行的基本单位，他是进程的一个实体，可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。

线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。

### **Java线程的状态转换**

![image-20210319152406724](https://i.loli.net/2021/03/19/PoS6n1y9CUuhlaZ.png)

其实是可以和操作系统中的进程状态相等比的

![image-20210319152822483](https://i.loli.net/2021/03/19/7PeuGOCntoImi3k.png)

Java中将操作系统中

1. ==可运行状态（就绪状态）/运行状态==转化为一个状态==Runnable==
2. ==休眠状态（阻塞状态）== 细分为了三种
   1. Blocked
   2. WAITING
   3. TIMED_WAITING

### sleep()和wait()的区别

1. sleep和wait都能暂停当前线程的执行（放弃CPU的占用），进行等待，但是join不释放共享资源(锁)，wait释放共享资源(锁)
2. sleep是作用在Thread上的，wait是作用在Object上的
3. sleep需要执行休眠时间，但是wait不需要，调用wait之后，随时都有可能被唤醒

```java
public static void main(String[] args) throws InterruptedException {
        Thread.sleep(1000);
        Object lock = new Object();
        synchronized (lock) {
            lock.wait();
        }
        lock.notifyAll();
    
}
```



### 线程安全的实现方法

#### 互斥同步

#### 非阻塞同步

是为了解决互斥同步所带来的线程上下文切换、线程阻塞唤醒所带来的开销。

**cas方法**

1. 共享变量的内存地址 V
2. 共享变量的旧的预期值 A
3. 准备更新的值 B

CAS指令执行时，当且仅当V符合 A时，处理器才会用B更新V的值，否则它就不执行更新。但是，不管是否更新了V的值，都会返回V的 旧值，上述的处理过程是一个原子操作，执行期间不会被其他线程中断。

#### 无同步方案

**主要是线程本地存储**

**threadlocal**

### 知道volatile的原理吗？

> Volatile是轻量级的synchronized。它在多处理器开发过程中保证的共享变量的**可见性**、**有序性**
>
> **可见性：** 当一个线程修改一个变量时，另一个线程能读到这个修改的值
>
> 当一个变量被volatile修饰的时候，Java内存模型会保证所有线程看到该变量的值是一致的。
>
> **有序性：** volatile通过禁止指令重排来实现。



**底层操作**

1. volatile修饰的变量**进行写操作**转换成汇编语言，会添加**Lock前缀的指令**

   **lock前缀的指令**在多核处理器的情况下，会引发以下的两个事情：

   1. 会将当前处理器缓存的数据，写回主内存
   2. 同时写回内存的操作，会使得其他处理器缓存的该内存地址的数据无效

2. 多处理器下，为了确保多处理器的缓存是一致的，会去实现缓存一致性协议，每个处理器通过**嗅探**在总线上传播的数据来检测自己缓存的数据是否过期。如果发现缓存的内存地址被修改，会将自身缓存的内存地址置为无效，然后下次操作该数据的时候，重新从主存中将数据重新读取缓存



**voaltile**的内存语义

* 可见性
  * 一个volatile变量的读，总是能看到（任意线程）对这个volatile变量的写
* 原子性
  * 仅仅对的任意单个变量的读/写具有原子性
  * volatile++ 等复合操作无法保证原子性
* 有序性
  * 因为volatile中规定了一些禁止指令重排的情况
  * 底层是用的是内存屏障

### **知道synchronized原理吗？**

> Java中每一个对象都可以作为锁，具体表现如下
>
> 1. 对于普通的同步方法，锁的是当前的实例对象
> 2. 对于静态的同步方法，锁的是该类的class对象
> 3. 对于同步代码块儿，锁的是括号内配置的对象

synchronized是java提供的原子性内置锁，使用synchronized之后，会在编译之后在同步的代码块前后加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。==他的作用主要就是实现原子性操作和解决共享变量的内存可见性、有序性问题。**同时synchronized也是可重入锁，**执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1==。此时其他竞争锁的线程则会进入等待队列中。执行monitorexit指令时则会把计数器-1，当计数器值为0时，则锁释放，处于等待队列中的线程再继续竞争锁。

synchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态，这种转换非常消耗性能。

==从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。==



*实际上大部分时候我认为说到monitorenter就行了，但是为了更清楚的描述，还是再具体一点*。

如果再深入到源码来说，synchronized实际上有两个队列waitSet和entryList。

1. 当多个线程进入同步代码块时，首先进入entryList
2. 有一个线程获取到monitor锁后，就赋值给当前线程，并且计数器+1
3. 如果线程调用wait方法，将释放锁，当前线程置为null，计数器-1，同时进入waitSet等待被唤醒，调用notify或者notifyAll之后又会进入entryList竞争锁
4. 如果线程执行完毕，同样释放锁，计数器-1，当前线程置为null

![sychronized简介](https://i.loli.net/2021/03/19/yEzfPDIsmOKTWtp.jpg)



### **那锁的优化机制了解吗？**

从JDK1.6版本之后，synchronized本身也在不断优化锁的机制，有些情况下他并不会是一个很重量级的锁了。优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。

锁的状态从低到高依次为**无锁->偏向锁->轻量级锁->重量级锁**，升级的过程就是从低到高，降级在一定条件也是有可能发生的。

**自旋锁**：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。

**自适应锁**：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由==前一次在同一个锁上的自旋时间和锁的持有者状态==来决定。

**锁消除**：锁消除指的是JVM检测到一些同步的代码块，==完全不存在数据竞争的场景==，也就是不需要加锁，就会进行锁消除。

**锁粗化**：锁粗化指的是有==很多操作都是对同一个对象进行加锁==，就会把锁的同步范围扩展到整个操作序列之外。

![image-20210407223038937](https://i.loli.net/2021/04/07/rnTBw8dRebyl6JX.png)

**无锁**

无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。

**偏向锁**

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。

>  **依据**：在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。==在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。==引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。

==偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。==

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

**轻量级锁**

是指当锁是偏向锁的时候，被另外的线程所访问，==偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。==

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

==若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。==

**重量级锁**

升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。

**关于偏向锁的hashcode问题**

![image-20210407221919799](https://i.loli.net/2021/04/07/m7z2np1WihDAd6t.png)

![IMG_3840](https://i.loli.net/2021/03/19/INbtBfJkX5DLidz.png)



### **那对象头具体都包含哪些内容？**

在我们常用的Hotspot虚拟机中，对象在内存中布局实际包含3个部分：

1. 对象头
2. 实例数据
3. 对齐填充

而对象头包含两部分内容，Mark Word中的内容会随着锁标志位而发生变化，所以只说存储结构就好了。

1. 对象自身运行时所需的数据，也被称为Mark Word，也就是用于轻量级锁和偏向锁的关键点。具体的内容包含对象的hashcode、分代年龄、轻量级锁指针、重量级锁指针、GC标记、偏向锁线程ID、偏向锁时间戳。
2. 存储类型指针，也就是指向类的元数据的指针，通过这个指针才能确定对象是属于哪个类的实例。

***如果是数组的话，则还包含了数组的长度***

![对象头](https://i.loli.net/2021/03/19/fc8jtqRprSVkNIT.jpg)



### **对于加锁，那再说下ReentrantLock原理？他和synchronized有什么区别？**

相比于synchronized，ReentrantLock需要显式的获取锁和释放锁，相对现在基本都是用JDK7和JDK8的版本，ReentrantLock的效率和synchronized区别基本可以持平了。他们的主要区别有以下几点：

1. 等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。
2. 公平锁：synchronized和ReentrantLock默认都是非公平锁，但是ReentrantLock可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。
3. 绑定多个条件：ReentrantLock可以同时绑定多个Condition条件对象。

ReentrantLock基于AQS(**AbstractQueuedSynchronizer 抽象队列同步器**)实现。别说了，我知道问题了，AQS原理我来讲。

AQS内部维护一个state状态位，尝试加锁的时候通过CAS(CompareAndSwap)修改值，如果成功设置为1，并且把当前线程ID赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为0，同时当前线程ID置为空。

![AQS-clh](https://i.loli.net/2021/03/19/rBz8bet9PONXFnM.jpg)



### **CAS的原理呢？**

CAS叫做CompareAndSwap，比较并交换，主要是通过处理器的指令来保证操作的原子性，它包含三个操作数：

1. 变量内存地址，V表示
2. 旧的预期值，A表示
3. 准备设置的新值，B表示

当执行CAS指令时，只有当V等于A时，才会用B去更新V的值，否则就不会执行更新操作。



### **那么CAS有什么缺点吗？**

CAS的缺点主要有3点：

**ABA问题**：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。

Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。

**循环时间长开销大**：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。

**只能保证一个共享变量的原子操作**：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。



### **好，说说HashMap原理吧？**

HashMap主要由数组和链表组成，他不是线程安全的。核心的点就是put插入数据的过程，get查询数据以及扩容的方式。JDK1.7和1.8的主要区别在于头插和尾插方式的修改，头插容易导致HashMap链表死循环，并且1.8之后加入红黑树对性能有提升。

**put插入数据流程**

往map插入元素的时候首先通过对key hash然后与数组长度-1进行与运算((n-1)&hash)，都是2的次幂所以等同于取模，但是位运算的效率更高。找到数组中的位置之后，如果数组中没有元素直接存入，反之则判断key是否相同，key相同就覆盖，否则就会插入到链表的尾部，如果链表的长度超过8，则会转换成红黑树，最后判断数组长度是否超过默认的长度*负载因子也就是12，超过则进行扩容。

![hashmap-put](https://i.loli.net/2021/03/19/fv1pa9P32gOEnVx.jpg)



**get查询数据**

查询数据相对来说就比较简单了，首先计算出hash值，然后去数组查询，是红黑树就去红黑树查，链表就遍历链表查询就可以了。

**resize扩容过程**

扩容的过程就是对key重新计算hash，然后把数据拷贝到新的数组。



### **那多线程环境怎么使用Map呢？ConcurrentHashmap了解过吗？**

多线程环境可以使用Collections.synchronizedMap同步加锁的方式，还可以使用HashTable，但是同步的方式显然性能不达标，而ConurrentHashMap更适合高并发场景使用。

ConcurrentHashmap在JDK1.8之前，引入了分段锁的概念，整体的存储结构如下图，在原有的数据结构基础上，拆分出了多个segment，每个segment下再挂载原来的entry（存放数据），每次执行操作，都需要先锁定元素在的segment，不需要锁定整个表，减小锁的粒度，并发度也就会得到提升。

![concurrenthashmap-segment](https://i.loli.net/2021/03/27/WBswk6NuhjAtEzU.jpg)



1.8则抛弃了Segment，改为使用CAS+synchronized+Node实现，同样也加入了红黑树，避免链表过长导致性能的问题。

**放弃原因：**

> 1. 使用segment之后，会增加concurrenthashmap的存储空间
> 2. 单个segment过大时，并发性能会急剧下降。

**查看put的过程：**

整体的流程和hashmap一样。不过有几个特殊的地方

1. put的元素所在对应hash桶数组中不存在的时候，直接cas进行写操作。Node中的value和next指针是volatile修饰，这也就保证了共享变量的可见性。所以在获取元素的时候，确保每次拿到的元素的都是最新的值。

   > 因为在JVM的内存模型中，每个线程有自己的工作内存，也就是栈中的局部变量表，它是主存的一份copy。因此，线程1对某个共享资源进行了更新操作，并写入到主存，而线程2的工作内存之中可能还是旧值，脏数据便产生了。Java中的volatile是用来解决上述问题，保证可见性，任意线程对volatile关键字修饰的变量进行更新时，会使其它线程中该变量的副本失效，需要从主存中获取最新值。

   ![image-20210327104924444](https://i.loli.net/2021/03/27/nybF2Mof7QvpkGX.png)

   ![image-20210327104746610](https://i.loli.net/2021/03/27/5YhHCjX3ZFq48ky.png)

   ![image-20210327104624603](https://i.loli.net/2021/03/27/fKctaLiyY8r5FlI.png)

2. 当put的元素在哈希桶中存在，并且不处于扩容状态时。使用synchronized锁定哈希数组中的第i个位置。接着进行double check，==类似于DCL单例模式的思想==。校验通过后，会遍历当前冲突链上的元素，并选择合适的位置进行put操作，此外，concurrenthashmap也沿用了hashmap中的解决冲突的方案，链表+红黑树。同时这里只有发生hash冲突的时候才会锁住头节点，其实是比分段锁更加细粒度的锁。只在特定场景下锁定其中一个哈希桶，降低锁的影响范围。

   ![image-20210327110041396](https://i.loli.net/2021/03/27/BlpKfPbF5cDLiuQ.png)

   

> Java Map针对并发场景解决方案的演进方向可以归结为，==从悲观锁到乐观锁，从粗粒度锁到细粒度锁。==这也可以作为我们在日常并发编程中的指导方针。



**1.7分段锁**

从结构上说，1.7版本的ConcurrentHashMap采用分段锁机制，里面包含一个Segment数组，Segment继承于ReentrantLock，Segment则包含HashEntry的数组，HashEntry本身就是一个链表的结构，具有保存key、value的能力能指向下一个节点的指针。

==实际上就是相当于每个Segment都是一个HashMap，默认的Segment长度是16==，也就是支持16个线程的并发写，Segment之间相互不会受到影响。



![concurrenthashmap-分段锁](https://i.loli.net/2021/03/19/YLyE6T2kPaVRGc9.jpg)



**put流程**

其实发现整个流程和HashMap非常类似，只不过是先定位到具体的Segment，然后通过ReentrantLock去操作而已，后面的流程我就简化了，因为和HashMap基本上是一样的。

1. 通过key计算hash，定位到segment，segment如果是空就先初始化
2. 使用ReentrantLock加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定获取锁成功
3. 遍历HashEntry，就是和HashMap一样，数组中key和hash一样就直接替换，不存在就再插入链表，链表同样



![concurrenthashmap-put](https://i.loli.net/2021/03/19/leM6iQUcJdxuIZW.jpg)



**get流程**

get也很简单，key通过hash定位到segment，再遍历链表定位到具体的元素上，需要注意的是value是volatile的，所以get是不需要加锁的。



**1.8CAS+synchronized**

1.8抛弃分段锁，转为用CAS+synchronized来实现，同样HashEntry改为Node，也加入了红黑树的实现。主要还是看put的流程。

![concurrenthashmap-cas-sync](https://i.loli.net/2021/03/19/TjVXuwQaIWKl7fR.jpg)



**put流程**

1. 首先计算hash，遍历node数组，如果node是空的话，就通过CAS+自旋的方式初始化
2. 如果当前数组位置是空则直接通过CAS自旋写入数据
3. 如果hash==MOVED，说明需要扩容，执行扩容
4. 如果都不满足，就使用synchronized写入数据，写入数据同样判断链表、红黑树，链表写入和HashMap的方式一样，key hash一样就覆盖，反之就尾插法，链表长度超过8就转换成红黑树

![concurrenthashmap-put2](https://i.loli.net/2021/03/19/TFgLzdt1rCuDO78.jpg)



**get查询**

get很简单，通过key计算hash，如果key hash相同就返回，如果是红黑树按照红黑树获取，都不是就遍历链表获取。



### **volatile原理知道吗？**

相比synchronized的加锁方式来解决共享变量的内存可见性问题，volatile就是更轻量的选择，他没有上下文切换的额外开销成本。使用volatile声明的变量，可以确保值被更新的时候对其他线程立刻可见。volatile使用内存屏障来保证不会发生指令重排，解决了内存可见性的问题。

我们知道，线程都是从主内存中读取共享变量到工作内存来操作，完成之后再把结果写回主内存，但是这样就会带来可见性问题。举个例子，假设现在我们是两级缓存的双核CPU架构，包含L1、L2两级缓存。

1. 线程A首先获取变量X的值，由于最初两级缓存都是空，所以直接从主内存中读取X，假设X初始值为0，线程A读取之后把X值都修改为1，同时写回主内存。这时候缓存和主内存的情况如下图。

![voaltile-基础](https://i.loli.net/2021/03/19/TBFLIhvl6OgSZw9.jpg)



1. 线程B也同样读取变量X的值，由于L2缓存已经有缓存X=1，所以直接从L2缓存读取，之后线程B把X修改为2，同时写回L2和主内存。这时候的X值入下图所示。
   那么线程A如果再想获取变量X的值，因为L1缓存已经有x=1了，所以这时候变量内存不可见问题就产生了，B修改为2的值对A来说没有感知。

![volatile-基础2](https://i.loli.net/2021/03/19/nztZD4kM7bCP9xG.jpg)

那么，如果X变量用volatile修饰的话，当线程A再次读取变量X的话，CPU就会根据缓存一致性协议强制线程A重新从主内存加载最新的值到自己的工作内存，而不是直接用缓存中的值。

再来说内存屏障的问题，volatile修饰之后会加入不同的内存屏障来保证可见性的问题能正确执行。这里写的屏障基于书中提供的内容，但是实际上由于CPU架构不同，重排序的策略不同，提供的内存屏障也不一样，比如x86平台上，只有StoreLoad一种内存屏障。

1. StoreStore屏障，保证上面的普通写不和volatile写发生重排序
2. StoreLoad屏障，保证volatile写与后面可能的volatile读写不发生重排序
3. LoadLoad屏障，禁止volatile读与后面的普通读重排序
4. LoadStore屏障，禁止volatile读和后面的普通写重排序

![volatile-内存屏障](https://i.loli.net/2021/03/19/lfzdRUPScvL8HAn.jpg)





### **那么说说你对JMM内存模型的理解？为什么需要JMM？**

本身随着CPU和内存的发展速度差异的问题，导致CPU的速度远快于内存，所以现在的CPU加入了高速缓存，高速缓存一般可以分为L1、L2、L3三级缓存。基于上面的例子我们知道了这导致了缓存一致性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和CPU的重排序导致了原子性和有序性的问题，JMM内存模型正是对多线程操作下的一系列规范约束，因为不可能让程序员的代码去兼容所有的CPU，通过JMM我们才==屏蔽了不同硬件和操作系统内存的访问差异==，这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行。

![JMM](https://i.loli.net/2021/03/19/wv5sRbQJf2UZp3B.jpg)





**原子性**：Java内存模型通过read、load、assign、use、store、write来保证原子性操作，此外还有lock和unlock，直接对应着synchronized关键字的monitorenter和monitorexit字节码指令。

**可见性**：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。

**有序性**：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。

**happen-before规则**

虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：

1. 单线程每个操作，happen-before于该线程中任意后续操作
2. volatile写happen-before于后续对这个变量的读
3. synchronized解锁happen-before后续对这个锁的加锁
4. final变量的写happen-before于final域对象的读，happen-before后续对final变量的读
5. 传递性规则，A先于B，B先于C，那么A一定先于C发生



### **说了半天，到底工作内存和主内存是什么？**

主内存可以认为就是物理内存，Java内存模型中实际就是虚拟机内存的一部分。而工作内存就是CPU缓存，他有可能是寄存器也有可能是L1\L2\L3缓存，都是有可能的。



### **说说ThreadLocal原理？**

ThreadLocal可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部副本变量就行了，做到了线程之间互相隔离，相比于synchronized的做法是用空间来换时间。

ThreadLocal有一个静态内部类ThreadLocalMap，ThreadLocalMap又包含了一个Entry数组，Entry本身是一个弱引用，他的key是指向ThreadLocal的弱引用，Entry具备了保存key value键值对的能力。

弱引用的目的是为了防止内存泄露，如果是强引用那么ThreadLocal对象除非线程结束否则始终无法被回收，弱引用则会在下一次GC的时候被回收。

但是这样还是会存在内存泄露的问题，假如key和ThreadLocal对象被回收之后，entry中就存在key为null，但是value有值的entry对象，但是永远没办法被访问到，同样除非线程结束运行。

但是只要ThreadLocal使用恰当，在使用完之后调用remove方法删除Entry对象，实际上是不会出现这个问题的。



![threadlocal](https://i.loli.net/2021/03/19/NXgFkawmribETft.jpg)





### **那引用类型有哪些？有什么区别？**

引用类型主要分为强软弱虚四种：

1. 强引用指的就是代码中普遍存在的赋值方式，比如A a = new A()这种。强引用关联的对象，永远不会被GC回收。
2. 软引用可以用SoftReference来描述，指的是那些有用但是不是必须要的对象。系统在发生内存溢出前会对这类引用的对象进行回收。
3. 弱引用可以用WeakReference来描述，他的强度比软引用更低一点，弱引用的对象下一次GC的时候一定会被回收，而不管内存是否足够。
4. 虚引用也被称作幻影引用，是最弱的引用关系，可以用PhantomReference来描述，他必须和ReferenceQueue一起使用，同样的当发生GC的时候，虚引用也会被回收。可以用虚引用来管理堆外内存。



### **线程池原理知道吗？**

首先线程池有几个核心的参数概念：

1. 最大线程数maximumPoolSize
2. 核心线程数corePoolSize
3. 活跃时间keepAliveTime
4. 阻塞队列workQueue
5. 拒绝策略RejectedExecutionHandler

当提交一个新任务到线程池时，具体的执行流程如下：

1. 当我们提交任务，线程池会根据corePoolSize大小创建若干任务数量线程执行任务
2. 当任务的数量超过corePoolSize数量，后续的任务将会进入阻塞队列阻塞排队
3. 当阻塞队列也满了之后，那么将会继续创建(maximumPoolSize-corePoolSize)个数量的线程来执行任务，如果任务处理完成，maximumPoolSize-corePoolSize额外创建的线程等待keepAliveTime之后被自动销毁
4. 如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

![线程池](https://i.loli.net/2021/03/19/ajPL4mToJUNYbWp.jpg)







### **拒绝策略有哪些？**

主要有4种拒绝策略：

1. AbortPolicy：直接丢弃任务，抛出异常，这是默认策略
2. CallerRunsPolicy：只用调用者所在的线程来处理任务
3. DiscardOldestPolicy：丢弃等待队列中最近的任务，并执行当前任务
4. DiscardPolicy：直接丢弃任务，也不抛出异常

### 线程池的异常捕捉

#### 原生处理机制

##### execute

调用`getThreadFactory().newThread(this)`创建工作线程，工作线程的底层实际是一个`Thread`类

查看 Thread 类的源码，发现了两个十分特别的方法，结合 JavaDoc 注释：

![image-20210411215043087](https://i.loli.net/2021/04/11/XT5MfCy2cSI7QgW.png)

1. `setUncaughtExceptionHandler()`：一个线程可以通过该方法来设置有未捕获的异常时程序的处理机制。如果没有设置，则 ThreadGroup 会作为默认的处理机制。

2. `dispatchUncaughtException()`: 当出现未捕获异常时调用该方法，该方法仅被 JVM 所调用。

`dispatchUncaughtException()`方法中的 uncaughtException() 方法，发现其属于 UncaughtExceptionHandler 接口，查看该接口实现类。目前只有一个实现类，就是` ThreadGroup`。

**异常未处理流程：**

1. JVM调用`dispatchUncaughtException()`方法
2. 默认情况下，`ThreadGroup`会作为默认的处理机制，即会调用 ThreadGroup#uncaughtException() 方法。
3. 对于`ThreadGroup`，在做了一系列判断之后，只要异常不是`ThreadDeath`子类，都会执行输出操作`System.err`
4. `System.err`仅会输出在控制台上，不会计入log

##### submit

工作线程的底层是一个`FutureTask`类

1. 线程池调用 submit() 方法底层是由 FutureTask 来执行的。
2. FutureTask 的 run() 方法在抛出异常时，调用 setException() 方法将异常保存下来。
3. 主线程通过调用 FutureTask 的 get() 方法，当执行出现异常时，被抛出。

#### 自定义处理机制

1. 线程池内业务逻辑添加try/catch方法
   1. 会使得整个业务逻辑编码不美观
2. 自定义ThreadPoolExecutor
3. 自定义ThreadGroup
   1. 自定义 ThreadGroup，这样就不会调用默认的 ThreadGroup，走 System.err 的逻辑了。

4. 设置UncaughtExceptionHandler
   1. 手动设置 UncaughtExceptionHandler。重新调整下我们的 Case，线程池的创建时传入我们自定义的 UncaughtExceptionHandler：


#### 总结

1. sumbit() 方式底层使用 FutureTask 执行任务，如果业务抛出异常，只有在调用 Future#get() 时才会被抛出。
2. execute() 方法底层使用 Thread 执行任务，如果业务抛出异常，默认采用 Sysstem.err 进行输出，只会打印在控制台和 tomcat 的 catalina.out 文件，不会输出到日志中。
3. sumbit() 方法处理异常，既可以在业务中进行手动 catch，也可以在调用 Future#get() 时手动 catch。
4. execute() 方法处理异常：
   1. 业务中手动 catch，每个业务地方都要写，最稳妥。
   2. 自定义 ThreadPoolExecutor 或者自定义 ThreadGroup，控制台会打印两遍日志。
   3. 设置 UncaughtExceptionHandler，控制台只打印一遍日志。

> 不论是自定义 ThreadPoolExecutor，或是自定义 ThreadGroup，或是设置 UncaughtExceptionHandler。到了这个地步说明线程执行已经出现了错误，此时整个任务已经挂掉了。
>
> 举个例子，例如你使用线程池进行一批数据计算，其中有一项数据出了问题。如果忽略出错的那一项数据是可接受的话，那么让整个任务都挂掉是不合适的。因此你应该在业务中手动 catch，来避免整个任务挂掉。
>
> 再举个例子，如果某个任务对正确性要求十分的高，如果出错整个系统都没有运行的必要了，那么就可以使用其他的几种处理方式。
>
> 可能例子举得不是十分恰当，但我想说明的是，技术最终要服务于业务，具体该使用哪种方式应该与你的业务场景有关。
>

### AQS

**核心思想：**

> 如果被请求的共享资源空闲，则当前线程成功获取锁，然后执行自己的任务。如果获取共享资源失败，则将线程信息封装成一个节点，加入同步队列。
>
> AQS通过volatile修饰的int变量state来表示同步状态，通过内部的CLH同步队列存储排队获取锁的线程。
>
> **对state的操作**
>
> > get/set/compareAndSet
>
> 同时对于资源的共享方式：独占式和共享式
>
> **独占式：**
>
> 1. 只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁
> 2. 公平锁:按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁
> 3. 当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
>
> **共享式：**
>
> 多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、 CountDownLatch、 CyclicBarrier、ReadWriteLock 
>
> 通过模板方法，我们继承aqs，然后重写指定的方法，就能实现自己的同步锁。

**以reentrantlock为例：（非公平锁）**

1. 新的线程想要获取锁，先通过cas获取锁，如果获取不成功，调用addWaiter方法将该线程封装成一个Node节点，然后加入到同步队列的队尾（cas）方式。
2. 然后调用acquireQueued方法，是的该节点以死循环的方式获取同步状态。如果获取不到，则阻塞节点中的线程，然后被阻塞的线程的唤醒只能通过前驱节点的出队或阻塞来实现。
3. 释放锁：调用tryrelease方法，同步状态的值-1，因为是可重入锁，所以只有当同步状态减至0的时候，才会释放锁。

#### reentrantlock（非公平锁）

**acquire方法:**

1. 首先会先调用`tryAcquire`方
   1. 如果返回true，则成功获取锁
   2. 如果返回false，则进行步骤二
2. 将当前线程以及相关的信息，封装成一个node节点，将节点添加至CLH同步队列队尾 `addWaiter()`方法
   1. CAS
3. 使用 `acquireQueued`，用于挂起线程，然后被唤醒去获取锁。
   1. 进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。



## JVM

这是面试专题系列第五篇JVM篇。

### **说说JVM的内存布局？**

![JVM运行时数据划分](https://i.loli.net/2021/04/09/vmUitFxhTVNbWLp.jpg)





Java虚拟机主要包含几个区域：

**堆**：堆Java虚拟机中最大的一块内存，是线程共享的内存区域，基本上所有的对象实例数组都是在堆上分配空间。堆区细分为Yound区年轻代和Old区老年代，其中年轻代又分为Eden、S0、S1 3个部分，他们默认的比例是8:1:1的大小。

**栈**：栈是线程私有的内存区域，每个方法执行的时候都会在栈创建一个栈帧，方法的调用过程就对应着栈的入栈和出栈的过程。每个栈帧的结构又包含局部变量表、操作数栈、动态连接、方法返回地址。

局部变量表用于存储方法参数和局部变量。当第一个方法被调用的时候，他的参数会被传递至从0开始的连续的局部变量表中。

操作数栈用于一些字节码指令从局部变量表中传递至操作数栈，也用来准备方法调用的参数以及接收方法返回结果。

动态连接用于将符号引用表示的方法转换为实际方法的直接引用。

**元数据**：在Java1.7之前，包含方法区的概念，常量池就存在于方法区（永久代）中，而方法区本身是一个逻辑上的概念，在1.7之后则是把常量池移到了堆内，1.8之后移除了永久代的概念(方法区的概念仍然保留)，实现方式则是现在的元数据。它包含类的元信息和运行时常量池。

Class文件就是类和接口的定义信息。

运行时常量池就是类和接口的常量池运行时的表现形式。

**本地方法栈**：主要用于执行本地native方法的区域

**程序计数器**：也是线程私有的区域，用于记录当前线程下虚拟机正在执行的字节码的指令地址



### **知道new一个对象的过程吗？**



![new对象过程](https://i.loli.net/2021/03/19/hR3nSrNMJzGPTFL.jpg)



当虚拟机遇见new关键字时候，实现判断当前类是否已经加载，如果类没有加载，首先执行类的加载机制，加载完成后再为对象分配空间、初始化等。

1. 首先校验当前类是否被加载，如果没有加载，执行类加载机制
2. 加载：就是从字节码加载成二进制流的过程
3. 验证：当然加载完成之后，当然需要校验Class文件是否符合虚拟机规范，跟我们接口请求一样，第一件事情当然是先做个参数校验了
4. 准备：为静态变量、常量赋默认值
5. 解析：把常量池中符号引用(以符号描述引用的目标)替换为直接引用(指向目标的指针或者句柄等)的过程
6. 初始化：执行static代码块(cinit)进行初始化，如果存在父类，先对父类进行初始化

*Ps：静态代码块是绝对线程安全的，只能隐式被java虚拟机在类加载过程中初始化调用！*(此处该有问题static代码块线程安全吗？)

当类加载完成之后，紧接着就是对象分配内存空间和初始化的过程

1. 首先为对象分配合适大小的内存空间
2. 接着为实例变量赋默认值
3. 设置对象的头信息，对象hash码、GC分代年龄、元数据信息等
4. 执行构造函数(init)初始化



### **知道双亲委派模型吗？**

类加载器自顶向下分为：

1. Bootstrap ClassLoader启动类加载器：默认会去加载JAVA_HOME/lib目录下的jar
2. Extention ClassLoader扩展类加载器：默认去加载JAVA_HOME/lib/ext目录下的jar
3. Application ClassLoader应用程序类加载器：比如我们的web应用，会加载web程序中ClassPath下的类
4. User ClassLoader用户自定义类加载器：由用户自己定义

当我们在加载类的时候，首先都会向上询问自己的父加载器是否已经加载，如果没有则依次向上询问，如果没有加载，则从上到下依次尝试是否能加载当前类，直到加载成功。



![classloader](https://i.loli.net/2021/03/19/k5runVyCvTJ8hSP.jpg)





### **说说有哪些垃圾回收算法？**

#### **标记-清除**

统一标记出需要回收的对象，标记完成之后统一回收所有被标记的对象，而由于标记的过程需要遍历所有的GC ROOT，清除的过程也要遍历堆中所有的对象，所以标记-清除算法的效率低下，同时也带来了内存碎片的问题。

#### **复制算法**

为了解决性能的问题，复制算法应运而生，它将内存分为大小相等的两块区域，每次使用其中的一块，当一块内存使用完之后，将还存活的对象拷贝到另外一块内存区域中，然后把当前内存清空，这样性能和内存碎片的问题得以解决。但是同时带来了另外一个问题，可使用的内存空间缩小了一半！

因此，诞生了我们现在的常见的年轻代+老年代的内存结构：Eden+S0+S1组成，因为根据IBM的研究显示，98%的对象都是朝生夕死，所以实际上存活的对象并不是很多，完全不需要用到一半内存浪费，所以默认的比例是8:1:1。

这样，在使用的时候只使用Eden区和S0S1中的一个，每次都把存活的对象拷贝另外一个未使用的Survivor区，同时清空Eden和使用的Survivor，这样下来内存的浪费就只有10%了。

如果最后未使用的Survivor放不下存活的对象，这些对象就进入Old老年代了。

*PS：所以有一些初级点的问题会问你为什么要分为Eden区和2个Survior区？有什么作用？就是为了节省内存和解决内存碎片的问题，这些算法都是为了解决问题而产生的，如果理解原因你就不需要死记硬背了*

#### **标记-整理**

针对老年代再用复制算法显然不合适，因为进入老年代的对象都存活率比较高了，这时候再频繁的复制对性能影响就比较大，而且也不会再有另外的空间进行兜底。所以针对老年代的特点，通过标记-整理算法，标记出所有的存活对象，让所有存活的对象都向一端移动，然后清理掉边界以外的内存空间。



### **那么什么是GC ROOT？有哪些GC ROOT？**

上面提到的标记的算法，怎么标记一个对象是否存活？简单的通过引用计数法，给对象设置一个引用计数器，每当有一个地方引用他，就给计数器+1，反之则计数器-1，但是这个简单的算法无法解决循环引用的问题。

Java通过可达性分析算法来达到标记存活对象的目的，定义一系列的GC ROOT为起点，从起点开始向下开始搜索，搜索走过的路径称为引用链，当一个对象到GC ROOT没有任何引用链相连的话，则对象可以判定是可以被回收的。

而可以作为GC ROOT的对象包括：

1. 栈中引用的对象
2. 静态变量、常量引用的对象
3. 本地方法栈native方法引用的对象

### **垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器？**

![GC算法-对应分区](https://i.loli.net/2021/03/19/GwhNT5X3lVYRjfI.jpg)



年轻代的垃圾收集器包含有Serial、ParNew、Parallell，老年代则包括Serial Old老年代版本、CMS、Parallel Old老年代版本和JDK11中的船新的G1收集器。

**Serial**：单线程版本收集器，进行垃圾回收的时候会STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停

**ParNew**：Serial的多线程版本，用于和CMS配合使用

**Parallel Scavenge**：可以并行收集的多线程垃圾收集器

**Serial Old**：Serial的老年代版本，也是单线程

**Parallel Old**：Parallel Scavenge的老年代版本

**CMS（Concurrent Mark Sweep）**：CMS收集器是以获取最短停顿时间为目标的收集器，相对于其他的收集器STW的时间更短暂，可以并行收集是他的特点，同时他基于标记-清除算法，整个GC的过程分为4步。

1. 初始标记：标记GC ROOT能关联到的对象（仅下一级），需要STW

   这个过程会 STW，但是跟 GC Root 直接关联的下级对象不会很多，因此这个过程其实很快。

2. 并发标记：根据上一步的结果，继续向下标识所有关联的对象，直到这条链上的最尽头。这个过程是多线程的，虽然耗时理论上会比较长，但是其它工作线程并不会阻塞，不需要STW

3. 重新标记：为啥还要再标记一次？因为第 2 步并没有阻塞其它工作线程，其它线程在标识过程中，很有可能会产生新的垃圾，需要STW

4. 并发清除：这里使用多线程以“Mark Sweep-标记清理”算法，把垃圾清掉，其它工作线程仍然能继续支行，不会造成卡顿。，不需要STW

从整个过程来看，并发标记和并发清除的耗时最长，但是不需要停止用户线程，而初始标记和重新标记的耗时较短，但是需要停止用户线程，总体而言，整个过程造成的停顿时间较短，大部分时候是可以和用户线程一起工作的。

**G1（Garbage First）**：G1收集器是JDK9的默认垃圾收集器，而且不再区分年轻代和老年代进行回收。



### **G1的原理了解吗？**

![G1回收器](https://i.loli.net/2021/03/19/BAG98SidrYypTo2.jpg)



G1作为JDK9之后的服务端默认收集器，且不再区分年轻代和老年代进行垃圾回收，他把内存划分为多个Region，每个Region的大小可以通过-XX：G1HeapRegionSize设置，大小为1~32M，对于大对象的存储则衍生出Humongous的概念，超过Region大小一半的对象会被认为是大对象，而超过整个Region大小的对象被认为是超级大对象，将会被存储在连续的N个Humongous Region中，G1在进行回收的时候会在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间优先回收收益最大的Region。

G1的回收过程分为以下四个步骤：

1. 初始标记：标记GC ROOT能关联到的对象，需要STW
2. 并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象
3. 最终标记：短暂暂停用户线程，再处理一次，需要STW
4. 筛选回收：更新Region的统计数据，对每个Region的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的Region中存活对象复制到空的Region，同时清理旧的Region。需要STW

总的来说除了并发标记之外，其他几个过程也还是需要短暂的STW，G1的目标是在停顿和延迟可控的情况下尽可能提高吞吐量。



### **什么时候会触发YGC和FGC？对象什么时候会进入老年代？**

当一个新的对象来申请内存空间的时候，如果Eden区无法满足内存分配需求，则触发YGC，使用中的Survivor区和Eden区存活对象送到未使用的Survivor区，如果YGC之后还是没有足够空间，则直接进入老年代分配，如果老年代也无法分配空间，触发FGC，FGC之后还是放不下则报出OOM异常。



![GC-过程](https://i.loli.net/2021/03/19/XuS5wkFlMWnemdb.jpg)



YGC之后，存活的对象将会被复制到未使用的Survivor区，如果S区放不下，则直接晋升至老年代。而对于那些一直在Survivor区来回复制的对象，通过-XX：MaxTenuringThreshold配置交换阈值，默认15次，如果超过次数同样进入老年代。

此外，还有一种动态年龄的判断机制，不需要等到MaxTenuringThreshold就能晋升老年代。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。



### **频繁FullGC怎么排查？**

这种问题最好的办法就是结合有具体的例子举例分析，如果没有就说一般的分析步骤。发生FGC有可能是内存分配不合理，比如Eden区太小，导致对象频繁进入老年代，这时候通过启动参数配置就能看出来，另外有可能就是存在内存泄露，可以通过以下的步骤进行排查：

1. jstat -gcutil或者查看gc.log日志，查看内存回收情况

![jstat](https://i.loli.net/2021/03/19/EqvchxDXu1jMdH3.jpg)

S0 S1 分别代表两个Survivor区占比

E代表Eden区占比，图中可以看到使用78%

O代表老年代，M代表元空间，YGC发生54次，YGCT代表YGC累计耗时，GCT代表GC累计耗时。

![jstat-detail](https://i.loli.net/2021/03/19/QtcN4LbwgsdpmhC.jpg)



[GC [FGC 开头代表垃圾回收的类型

PSYoungGen: 6130K->6130K(9216K)] 12274K->14330K(19456K), 0.0034895 secs代表YGC前后内存使用情况

Times: user=0.02 sys=0.00, real=0.00 secs，user表示用户态消耗的CPU时间，sys表示内核态消耗的CPU时间，real表示各种墙时钟的等待时间

这两张图只是举例并没有关联关系，比如你从图里面看能到是否进行FGC，FGC的时间花费多长，GC后老年代，年轻代内存是否有减少，得到一些初步的情况来做出判断。

1. dump出内存文件再具体分析，比如通过jmap命令jmap -dump:format=b,file=dumpfile pid，导出之后再通过**Eclipse Memory Analyzer**等工具进行分析，定位到代码，修复

这里还会可能存在一个提问的点，比如CPU飙高，同时FGC怎么办？办法比较类似

1. 找到当前进程的pid，top -p pid -H 查看资源占用，找到线程
2. printf “%x\n” pid，把线程pid转为16进制，比如0x32d
3. jstack pid|grep -A 10 0x32d查看线程的堆栈日志，还找不到问题继续
4. dump出内存文件用MAT等工具进行分析，定位到代码，修复



### **JVM调优有什么经验吗？**

要明白一点，所有的调优的目的都是为了用更小的硬件成本达到更高的吞吐，JVM的调优也是一样，通过对垃圾收集器和内存分配的调优达到性能的最佳。

#### **简单的参数含义**

首先，需要知道几个主要的参数含义。

![JVM调优](https://i.loli.net/2021/04/09/Gd4hLqltBXbKU1e.jpg)



1. -Xms设置初始堆的大小，-Xmx设置最大堆的大小
2. -XX:NewSize年轻代大小，-XX:MaxNewSize年轻代最大值，-Xmn则是相当于同时配置-XX:NewSize和-XX:MaxNewSize为一样的值
3. -XX:NewRatio设置年轻代和年老代的比值，如果为3，表示年轻代与老年代比值为1:3，默认值为2
4. -XX:SurvivorRatio年轻代和两个Survivor的比值，默认8，代表比值为8:1:1
5. -XX:PretenureSizeThreshold 当创建的对象超过指定大小时，直接把对象分配在老年代。
6. -XX:MaxTenuringThreshold设定对象在Survivor复制的最大年龄阈值，超过阈值转移到老年代
7. -XX:MaxDirectMemorySize当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC

#### **调优**

1. 为了打印日志方便排查问题最好开启GC日志，开启GC日志对性能影响微乎其微，但是能帮助我们快速排查定位问题。-XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:gc.log
2. 一般设置-Xms=-Xmx，这样可以获得固定大小的堆内存，减少GC的次数和耗时，可以使得堆相对稳定
3. -XX:+HeapDumpOnOutOfMemoryError让JVM在发生内存溢出的时候自动生成内存快照，方便排查问题
4. -Xmn设置年轻代的大小，太小会增加YGC，太大会减小老年代大小，一般设置为整个堆的1/4到1/3
5. 设置-XX:+DisableExplicitGC禁止系统System.gc()，防止手动误触发FGC造成问题



直接过一遍示例：

1. 客户1办理业务，选择编号最小、空闲的窗口：1号窗口
2. 客户2办理业务，选择编号最小、空闲的窗口：2号窗口
3. 客户3办理业务，选择编号最小、空闲的窗口：3号窗口
4. 客户4办理业务，选择编号最小、空闲的窗口：

